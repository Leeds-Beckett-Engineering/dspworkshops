{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053ff5cd-206e-4738-bf20-1ade773e740d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Workshop 5: LTI Systems and Convolution\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This workshop investigates linear time-invariant (LTI) systems. LTI systems are relevant to many branches of science, engineering and maths. For example, many types of mechanical system and many electrical and electronic circuits (e.g. amplifiers and filters) are LTI systems.\n",
    "\n",
    "An important property of LTI systems is that they always obey the \"principle of superposition\".\n",
    "\n",
    "* Explain the meaning of the term \"superposition\" in your own words and discuss some examples where the \"principle of superposition\" applies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69518345",
   "metadata": {},
   "source": [
    "  *Answer*:\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c05ae20",
   "metadata": {},
   "source": [
    "The behaviour of an LTI system is completely defined by its \"impulse response\". This is the characteristic output seen when you apply a quick single pulse at the input. The impulse response is time-invariant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc439278-97d2-4520-bbfe-41165b3f2e78",
   "metadata": {},
   "source": [
    "## Using principle of superposition\n",
    "\n",
    "<img src=\"images/workshop5figs-1.png\" width=800 alt=\"x1[n] and h[n] signals\">\n",
    "\n",
    "Above, a signal **x1[n]** is shown which consists of three separate impulses with amplitudes of 4, 12 and 8. Also shown is an impulse response **h[n]** which consists of the direct response (at n=0) and three reflections with amplitudes of 0.5, 0.25 and 0.125.\n",
    "\n",
    "If we take **x1** as a audio signal and h as a room response and play **x1** into the space represented by **h** we can work out the result. Answer the following questions (this is similar to example from the lecture):\n",
    "\n",
    "1. What do you think will be the timespan of the resulting sound? When will the last reflection occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc435454-37c3-4ce7-be02-8ee4f0d8f508",
   "metadata": {},
   "source": [
    "#### Q1 answer\n",
    "\n",
    "*Timespan*:\n",
    "\n",
    "*Last reflection*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9433bd-ba47-4c79-ac03-7c1f8c0b06f7",
   "metadata": {},
   "source": [
    "2. At what time do you guess the loudest sound will occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc1e6f-8b68-46d5-8c2c-f21cfe8eb473",
   "metadata": {},
   "source": [
    "#### Q2 answer\n",
    "\n",
    "*Last sound occurs at* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e0a60e-aaf2-4e6e-bf0b-2a6362bca5fe",
   "metadata": {},
   "source": [
    "3. Check your answers by constructing a stem diagram for the resultant sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b372612-27b3-4373-bf2b-83345f197c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code  stem diagram for the resultant sound for Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc8828-69b6-49ec-baa2-582eafd38265",
   "metadata": {},
   "source": [
    "<img src=\"images/workshop5figs-2.png\" width=500 alt=\"x2[n] signal\">\n",
    "\n",
    "Above, a new audio signal **x2[n]** is shown which consists of four separate impulses with amplitudes of 84, 16, 8 and 4 units. Using the impulse response **h[n]** answer the following questions:\n",
    "\n",
    "4. What do you think will be the timespan of the resulting sound? When will the last reflection occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce14671c-f579-4e70-9afa-05a1d18a88d5",
   "metadata": {},
   "source": [
    "#### Q4 answer\n",
    "\n",
    "*Timespan*:\n",
    "\n",
    "*Last reflection*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e0aee-7c2e-4790-aece-36a27a3c8e3e",
   "metadata": {},
   "source": [
    "5. At what time do you guess the loudest sound will occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050fccd-95f1-4d61-8600-5e14654dffe9",
   "metadata": {},
   "source": [
    "#### Q5 answer\n",
    "\n",
    "*Last sound occurs at* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ceb44-2db5-4921-b75c-e972b1701eea",
   "metadata": {},
   "source": [
    "6. Check your answers by constructing a stem diagram for the resultant sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e75f64-2d48-4c58-a082-245a200b7c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code  stem diagram for the resultant sound for Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fec11c-6286-4655-b544-3731f17297bc",
   "metadata": {},
   "source": [
    "<img src=\"images/workshop5figs-3.png\" width=500 alt=\"x3[n] signal\">\n",
    "\n",
    "Above, a new audio signal **x3[n]** is shown which has a steady constant amplitude as shown for seven samples. Using the impulse response **h[n]** answer the following questions:\n",
    "\n",
    "7. What do you think will be the timespan of the resulting sound? When will the last reflection occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c229cd-36d0-4210-a7de-2d4b7d442c7b",
   "metadata": {},
   "source": [
    "#### Q7 answer\n",
    "\n",
    "*Timespan*:\n",
    "\n",
    "*Last reflection*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a99646-635d-455d-8c26-81a449f6f6d6",
   "metadata": {},
   "source": [
    "8. At what time do you guess the loudest sound will occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9b08d-456a-4de3-b5ec-041c26116fc9",
   "metadata": {},
   "source": [
    "#### Q8 answer\n",
    "\n",
    "*Last sound occurs at* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce851f-4ef0-4900-b7e0-af13f10b8fe6",
   "metadata": {},
   "source": [
    "9. Check your answers by constructing a stem diagram for the resultant sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf29c33-d292-49d6-926f-93ddd7118707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code  stem diagram for the resultant sound for Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bf30e-5dff-4252-87fa-765156211aa5",
   "metadata": {},
   "source": [
    "## The convolution formula\n",
    "\n",
    "Given we know that the discrete time convolution formula is\n",
    "\n",
    "$$\n",
    "y[n] = \\sum_{k=0}^{n} x[k]h[n-k]\\qquad\\text{for }n = 0, 1, 2, ...\n",
    "$$\n",
    "\n",
    "You need to complete the expressions for each of the output samples up to a value of $n = 9$ with $y[0]$ already done:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a9203",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "y[0] &= x[0]h[0] \\\\\n",
    "y[1] &= \\\\\n",
    "y[2] &= \\\\\n",
    "y[3] &= \\\\\n",
    "y[4] &= \\\\\n",
    "y[5] &= \\\\\n",
    "y[6] &= \\\\\n",
    "y[7] &= \\\\\n",
    "y[8] &= \\\\\n",
    "y[9] &=\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8e357-4b7b-40a9-be48-90797b95ed3f",
   "metadata": {},
   "source": [
    "## Implementing convolution using software\n",
    "\n",
    "The convolution formula in its discrete time form (the form with $\\sum$) is ideally suited to implementation in electronic devices. Convolution can be performed especially fast and accurately within a Digital Signal Processing (DSP) device. It can also be easily carried out using a general purpose computer. This section uses Python (with scipy & numpy) to implement the convolution of an audio signal and an impulse response.\n",
    "\n",
    "The code section below calculates the convolution of a signal **x1** with an impulse response **h** and displays **x1**, **h** and output **y** as stem graphs. Adapting the code as needed, use it to calculate and confirm your results for the examples you worked out above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d30d8c-da5f-4094-8652-730201c7499f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code for convolution\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n = np.linspace(0, 9, 10)\n",
    "h = np.array([1, 0.5, 0.25, 0.125, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "plt.stem(\n",
    "    n, h, basefmt=\"none\"\n",
    ")  # display the filtered waveform\n",
    "plt.grid()\n",
    "plt.xticks(\n",
    "    np.arange(0, 10, step=1), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    ")\n",
    "plt.title(\"h[n]\")\n",
    "plt.xlim([-0.1, 9.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354692e2-e942-4db6-bbba-0812d6e0c3d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array([4, 12, 8, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "plt.stem(\n",
    "    n, x1, basefmt=\"None\"\n",
    ")  # display the filtered waveform\n",
    "plt.grid()\n",
    "plt.xticks(\n",
    "    np.arange(0, 10, step=1), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    ")\n",
    "plt.title(\"x1[n]\")\n",
    "plt.xlim([-0.1, 9.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f0d61-87c9-45bc-94b2-c092365a6b69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.convolve(x1, h)\n",
    "n_y = np.linspace(0, (len(y) - 1), len(y))\n",
    "\n",
    "plt.stem(\n",
    "    n_y, y, basefmt=\"none\"\n",
    ")  # display the filtered waveform\n",
    "plt.grid()\n",
    "plt.xticks(\n",
    "    np.arange(0, 19, step=1),\n",
    "    [\n",
    "        0,\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        11,\n",
    "        12,\n",
    "        13,\n",
    "        14,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        18,\n",
    "    ],\n",
    ")\n",
    "plt.title(\"y[n] = x1[n] * h[n]\")\n",
    "plt.xlim([-0.5, 18.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e94eee-1f59-47b2-b7aa-51cdf72cb6c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Using the above code as a guide now create code to show the results of convolving **x2[n]** and **x3[n]** with **h[n]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce4fac-6795-4cae-bb26-99ac1d1dcd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve x2[]n with h[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545848cc-c249-4845-949c-d5377efd2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve x3[n] with h[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94af38-4aa4-400f-a5ef-7c13da510f0a",
   "metadata": {},
   "source": [
    "## A practical convolution reverb program\n",
    "\n",
    "THe discrete time signals in examples above can be played back as an audio file provided we use an appropriate sample rate. The Python cod ebelow does the same convolution as the first example but with a new sample rate. Run this code and then create adoaptions of it for the other two signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575d881-e104-4fad-8fde-090849daea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution 2 - calulates x1 * h and writes result to an audio file\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rn = np.linspace(1, 5000, 5000)\n",
    "rh = np.zeros_like(rn)\n",
    "rh[0] = 1\n",
    "rh[500] = 0.5\n",
    "rh[1000] = 0.25\n",
    "rh[1500] = 0.125\n",
    "\n",
    "plt.stem(\n",
    "    rn, rh, basefmt=\"none\"\n",
    ")  # display the filtered waveform\n",
    "plt.grid()\n",
    "plt.title(\"h[n]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f206a4-9b8c-4a30-a886-6b6fc3fd60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx1 = np.zeros_like(rn)\n",
    "rx1[0] = 4\n",
    "rx1[500] = 12\n",
    "rx1[1000] = 8\n",
    "plt.stem(\n",
    "    rn, rx1, basefmt=\"none\"\n",
    ")  # display the filtered waveform\n",
    "plt.grid()\n",
    "plt.title(\"x1[n]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20d7a3-431d-42f7-a043-bc8e626b9317",
   "metadata": {},
   "outputs": [],
   "source": [
    "ry = np.convolve(rx1, rh)\n",
    "rn_y = np.linspace(1, len(ry), len(ry))\n",
    "\n",
    "plt.stem(\n",
    "    rn_y, ry, basefmt=\"none\"\n",
    ")  # display the filtered waveform\n",
    "plt.grid()\n",
    "plt.title(\"y[n] = x1[n] * h[n]\")\n",
    "plt.show()\n",
    "\n",
    "ry = ry * 0.05  # scales output to avoid clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fd2d8-90c6-4c49-9a94-3d0fcc33a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "\n",
    "audio = Audio(data=ry, rate=8000)\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8066e-f7bc-4b45-b09a-9d1d812fdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "newoutput = \"newx1.wav\"\n",
    "wavfile.write(newoutput, data=ry, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c26d84-77a3-4966-8063-ef7eb29e7365",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code to create reverb with x2[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e6693-cfbf-4701-b948-1102c02f0122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create reverb with x3[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ff937-1c01-47df-a037-f4f8627f9b0a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Further work\n",
    "\n",
    "1. In [`scipy.io`](https://docs.scipy.org/doc/scipy/reference/io.html#module-scipy.io.wavfile) as well as the write command there is a read command for wav files.\n",
    "   \n",
    "    a. Develop Python code to allow you to input an audio signal x from a file and output the result of convolving it with h. You can use the some of the wave files in the wav_files directory for the inputs. You will however possibly wish to change h so it is at a similar sample rate to the provided files. Use Workshop 1 to help you work out what the sampel (framerate) of the wave files is  \n",
    "    b. Develop Python code to create your own artifical impulse responses. Consider how you would create an impulse response to simulate an enclosed space of a specific size and shape. Explore the effects of your simulated spaces on short test signals (clicks, chirps or drumbeats), music and speech.\n",
    "   \n",
    "2. Modify your code to use a captured impulse response. There are a few interesting responses [here](https://space-net.hosted.york.ac.uk/node/50/) which is a resource developed at the University of York to share acoustic impulse responses including the 7s reverbaration at York Minister. *Note* the idea here is to cerate code that takes in two files - one for the audio signal x and one for the impulse response h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd089ff-8661-46dd-b60f-e5ba30383adf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q1A: code for taking x in from a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76d7dd-ace7-410c-a55c-9899fa4cc7d1",
   "metadata": {},
   "source": [
    "Notes on design for Q1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8b312-ef2e-4fa6-851c-61690e642520",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q1B: extension to above code to include creating own impulse response and using on an imported audio signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16ae0b-cce1-4eff-b57c-6baefcb84bfb",
   "metadata": {},
   "source": [
    "Notes on design for Q1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ec963-d398-4052-b2d3-c63b98a339e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q2: Code to take in files for both audio signal x and impulse response h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f079e49-3d75-4164-8210-a828597c7543",
   "metadata": {},
   "source": [
    "Notes on design for Q2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
